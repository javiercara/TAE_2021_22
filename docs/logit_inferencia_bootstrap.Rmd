---
title: 'Bootstrap en el modelo de regresión logística'
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
---

# Bootstrap para regresión

Cuando hablamos de problemas de regresión, los datos adoptan la siguiente forma:

$$
\begin{matrix}
y_1 & x_{11} & x_{21} & \cdots & x_{k1} \\
y_2 & x_{12} & x_{22} & \cdots & x_{k2} \\
\cdots & \cdots & \cdots & \cdots & \cdots \\
y_n & x_{11} & x_{2n} & \cdots & x_{kn} \\
\end{matrix}
$$

que también se pueden representar como $(y_1,x_1), (y_2,x_2), \cdots, (y_n,x_n)$, donde $x_i = \{x_{1i}, x_{1i}, \cdots, x_{1i}\}$. Podemos generar B muestras bootstrap diferentes de dos maneras:

- bootstrap empírico: Tratamos a cada par $(y_i,x_i)$ como un objeto y remuetreamos con reemplazamiento en el conjunto $(y_1,x_1), (y_2,x_2), \cdots, (y_n,x_n)$ para obtener las B réplicas bootstrap.

$$
\begin{matrix}
(y_1^{*(1)},x_1^{*(1)}), & (y_2^{*(1)},x_2^{*(1)}), & \cdots, & (y_n^{*(1)},x_n^{*(1)}) \\
(y_1^{*(2)},x_1^{*(2)}), & (y_2^{*(2)},x_2^{*(2)}), & \cdots, & (y_n^{*(2)},x_n^{*(2)}) \\
 & \vdots & &  \\
(y_1^{*(B)},x_1^{*(B)}), & (y_2^{*(B)},x_2^{*(B)}), & \cdots, & (y_n^{*(B)},x_n^{*(B)})
\end{matrix}
$$

- bootstrap de los residuos: se estima el modelo y se calculan los residuos $e_i = y_i - \hat{y}_i$. A continuación se remuestrean los residuos B veces con reemplazamiento:

$$
\begin{matrix}
e_1^{*(1)}, & e_2^{*(1)}, & \cdots, & e_n^{*(1)} \\
e_1^{*(2)}, & e_2^{*(2)}, & \cdots, & e_n^{*(2)} \\
& \vdots & & \\
e_1^{*(B)}, & e_2^{*(B)}, & \cdots, & e_n^{*(B)}
\end{matrix}
$$

Finalmente se obtienen las nuevas muestras bootstrap mediante $y_i^{*(b)} = \hat{y}_i + e_i^{*(b)}, \quad b = 1,\cdots,B$.

En el modelo de regresión lineal se prefiere utilizar el bootstrap de los residuos, ya que se elimina el efecto de atípicos, puntos influyentes, ... sin embargo, en regresión logística los residuos son del tipo {0,1}, por lo que se tiene que aplicar el bootstrap empírico.

# Bootstrap en regresión logística

Vamos a calcular, utilizando bootstrap, el standard error y los intervalos de confianza para los parámetros del modelo:

```{r}
d = read.csv("datos/MichelinNY.csv")
str(d)
```

Bootstap:

```{r warning=FALSE}
set.seed(99)
B = 500
n = nrow(d)
beta_e = matrix(0, nrow = B, ncol = 5)
for (b in 1:B){
  pos_b = sample(1:n, n, replace = T)
  d_b = d[pos_b,]
  m_b = glm(InMichelin ~ Food + Decor + Service + Price, data = d_b, family = binomial)
  beta_e[b,] = coef(m_b)
}
```

- Standard errors calculados con bootstrap:

```{r}
apply(beta_e,2,sd)
```

- Invervalos de confianza calculados con bootstrap:

```{r}
alfa = 0.05
apply(beta_e,2,quantile, probs = c(alfa/2,1-alfa/2))
```

Se puede comprobar que los resultados de bootstrap concuerdan con los obtenidos mediante la distribuciones asintóticas.
